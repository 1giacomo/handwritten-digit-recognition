{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten digit recognition\n",
    "\n",
    "Handwritten digit recognition (MNIST df) from sratch\n",
    "\n",
    "## MNIST Database\n",
    "\n",
    "## 2-Layer Neural Network\n",
    "\n",
    "### Layer 0\n",
    "\n",
    "784 nodes -> each one for a pixel\n",
    "\n",
    "### Layer 1\n",
    "\n",
    "10 nodes -> Hidden Layer\n",
    "\n",
    "### Layer 2\n",
    "\n",
    "10 nodes -> Output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./mnist/mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.608  0.609  0.610  \\\n",
       "0  0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1  4  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  9  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_, m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation\n",
    "\n",
    "$$\n",
    "A^{[0]} = x\n",
    "$$\n",
    "\n",
    "$$\n",
    "Z^{[1]} = W^{[1]}*A^{[1]} + b^{[1]}\n",
    "$$\n",
    "\n",
    "#### Apply an Activation Function\n",
    "\n",
    "$$\n",
    "A^{[1]} = g(Z^{[1]}) = ReLu(Z^{[1]})\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^{[1]} = g(Z^{[1]}) = \\text{ReLu}(Z^{[1]})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{ReLu}(x) = \\begin{cases}\n",
    "      x & \\text{if } x \\geq 0 \\\\\n",
    "      0 & \\text{if } x < 0\n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Z^{[2]} = W^{[2]}*A^{[1]} + b^{[2]}\n",
    "$$\n",
    "\n",
    "#### Apply another Activation Function\n",
    "\n",
    "$$\n",
    "A^{[2]} = softmax(Z^{[2]})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward propagation\n",
    "\n",
    "#### Layer 2\n",
    "\n",
    "$$\n",
    "dZ^{[2]} = A^{[2]} - Y\n",
    "$$\n",
    "\n",
    "$$\n",
    "dW^{[2]} = 1/m*dZ^{[2]} * A^{[1]T}\n",
    "$$\n",
    "\n",
    "$$\n",
    "db^{[2]} = 1/m*\\sum_{}dZ^{[2]}\n",
    "$$\n",
    "\n",
    "#### Layer 1\n",
    "\n",
    "$$\n",
    "dZ^{[1]} = W^{[2]T} * dZ^{[2]} * g'(Z^{[1]})\n",
    "$$\n",
    "\n",
    "$$\n",
    "dW^{[1]} = 1/m*dZ^{[1]} * X^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "db^{[2]} = 1/m*\\sum_{}dZ^{[1]}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update parameters\n",
    "\n",
    "$$\n",
    "W^{[1]} := W^{[1]} - \\alpha dbW^{[1]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^{[1]} := b^{[1]} - \\alpha dbb^{[1]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W^{[2]} := W^{[2]} - \\alpha dbW^{[2]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^{[2]} := b^{[2]} - \\alpha dbb^{[2]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha = learning \\space rate\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(\n",
    "            W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[3 3 2 ... 3 3 6] [4 2 9 ... 9 8 5]\n",
      "0.1164426515703656\n",
      "Iteration:  10\n",
      "[7 3 7 ... 7 9 9] [4 2 9 ... 9 8 5]\n",
      "0.152256817912168\n",
      "Iteration:  20\n",
      "[7 3 7 ... 7 9 9] [4 2 9 ... 9 8 5]\n",
      "0.21907150968660485\n",
      "Iteration:  30\n",
      "[7 3 7 ... 7 9 6] [4 2 9 ... 9 8 5]\n",
      "0.27646231292055795\n",
      "Iteration:  40\n",
      "[7 3 7 ... 7 9 6] [4 2 9 ... 9 8 5]\n",
      "0.3376497906744182\n",
      "Iteration:  50\n",
      "[7 3 7 ... 9 9 6] [4 2 9 ... 9 8 5]\n",
      "0.39090493059204395\n",
      "Iteration:  60\n",
      "[8 3 7 ... 9 9 6] [4 2 9 ... 9 8 5]\n",
      "0.43709215410430685\n",
      "Iteration:  70\n",
      "[8 3 7 ... 9 9 6] [4 2 9 ... 9 8 5]\n",
      "0.4795335514161257\n",
      "Iteration:  80\n",
      "[8 3 7 ... 9 5 6] [4 2 9 ... 9 8 5]\n",
      "0.5202461058662011\n",
      "Iteration:  90\n",
      "[8 3 7 ... 9 5 6] [4 2 9 ... 9 8 5]\n",
      "0.553060221359684\n",
      "Iteration:  100\n",
      "[8 3 7 ... 9 5 6] [4 2 9 ... 9 8 5]\n",
      "0.5806708588281158\n",
      "Iteration:  110\n",
      "[8 2 7 ... 9 5 5] [4 2 9 ... 9 8 5]\n",
      "0.604061085781115\n",
      "Iteration:  120\n",
      "[8 2 7 ... 9 5 5] [4 2 9 ... 9 8 5]\n",
      "0.6245868574043628\n",
      "Iteration:  130\n",
      "[8 2 7 ... 9 5 5] [4 2 9 ... 9 8 5]\n",
      "0.6425024152951745\n",
      "Iteration:  140\n",
      "[8 2 7 ... 9 5 5] [4 2 9 ... 9 8 5]\n",
      "0.6589264224817369\n",
      "Iteration:  150\n",
      "[8 2 7 ... 9 5 5] [4 2 9 ... 9 8 5]\n",
      "0.674757199274564\n",
      "Iteration:  160\n",
      "[8 2 7 ... 9 5 5] [4 2 9 ... 9 8 5]\n",
      "0.6889269309649316\n",
      "Iteration:  170\n",
      "[8 2 7 ... 9 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7023508873031746\n",
      "Iteration:  180\n",
      "[8 2 7 ... 9 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7141137985389583\n",
      "Iteration:  190\n",
      "[8 2 7 ... 9 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7242665129917456\n",
      "Iteration:  200\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7338429464906184\n",
      "Iteration:  210\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7429108967948609\n",
      "Iteration:  220\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7513686672655469\n",
      "Iteration:  230\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7593010051017813\n",
      "Iteration:  240\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7670468990999847\n",
      "Iteration:  250\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7729961524771606\n",
      "Iteration:  260\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7781996305022119\n",
      "Iteration:  270\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7833861590874421\n",
      "Iteration:  280\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7885557382328514\n",
      "Iteration:  290\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7931659858641672\n",
      "Iteration:  300\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.7980304750927982\n",
      "Iteration:  310\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8019457956914524\n",
      "Iteration:  320\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8054034814149392\n",
      "Iteration:  330\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8090137120968152\n",
      "Iteration:  340\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.812352751741555\n",
      "Iteration:  350\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8150646621129172\n",
      "Iteration:  360\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8182003084798047\n",
      "Iteration:  370\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8210986626891981\n",
      "Iteration:  380\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8234885337039611\n",
      "Iteration:  390\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8260648485567552\n",
      "Iteration:  400\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.828251326293666\n",
      "Iteration:  410\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8301327141137985\n",
      "Iteration:  420\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8319802030542891\n",
      "Iteration:  430\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8340480347124527\n",
      "Iteration:  440\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8359463719724063\n",
      "Iteration:  450\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8377769114730759\n",
      "Iteration:  460\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8393023610569671\n",
      "Iteration:  470\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8409125578399634\n",
      "Iteration:  480\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8425058051831387\n",
      "Iteration:  490\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8438787098086408\n",
      "Iteration:  500\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8455228054712792\n",
      "Iteration:  510\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8467770640180342\n",
      "Iteration:  520\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8480482720046102\n",
      "Iteration:  530\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8494889743893964\n",
      "Iteration:  540\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8505228902184783\n",
      "Iteration:  550\n",
      "[8 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8517771487652334\n",
      "Iteration:  560\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8529805589925253\n",
      "Iteration:  570\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8538788793030391\n",
      "Iteration:  580\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.855048390650689\n",
      "Iteration:  590\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8558619637620977\n",
      "Iteration:  600\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8568111323920744\n",
      "Iteration:  610\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8576925032627671\n",
      "Iteration:  620\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8585738741334599\n",
      "Iteration:  630\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8595908405227207\n",
      "Iteration:  640\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8602518686757402\n",
      "Iteration:  650\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8609467957084018\n",
      "Iteration:  660\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8618620654587366\n",
      "Iteration:  670\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8627603857692503\n",
      "Iteration:  680\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8635231105611959\n",
      "Iteration:  690\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8643027847929626\n",
      "Iteration:  700\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8649977118256241\n",
      "Iteration:  710\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8657943354972119\n",
      "Iteration:  720\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8666757063679046\n",
      "Iteration:  730\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8670655434837878\n",
      "Iteration:  740\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8675909761182393\n",
      "Iteration:  750\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8683537009101849\n",
      "Iteration:  760\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8688960829844574\n",
      "Iteration:  770\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8694045661790878\n",
      "Iteration:  780\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8701333920913914\n",
      "Iteration:  790\n",
      "[4 2 7 ... 4 5 5] [4 2 9 ... 9 8 5]\n",
      "0.8705401786470958\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "\n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 15005\n",
      "Prediction:  [3]\n",
      "Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa50lEQVR4nO3dfWxV9R3H8c/loRfU9tZa29srTwUEFhE2ELoGrDA62m5hPM2I4w8wRodrjYKCqZniU1aHySQaBvtjgRlFECMQ2EKC1ZZsKxie0pnNhjZ1lEHLIOFeKLZg+9sfxDsvFPCUe/n24f1KfknvOed7z5efJ/147jn31OeccwIA4CbrY90AAKB3IoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgop91A5drb2/X8ePHlZycLJ/PZ90OAMAj55zOnj2rUCikPn2ufp7T5QLo+PHjGjx4sHUbAIAb1NDQoEGDBl11fZf7CC45Odm6BQBAHFzv93nCAmjNmjUaNmyYBgwYoJycHH322WffqY6P3QCgZ7je7/OEBNDmzZu1bNkyrVy5UgcPHtT48eNVUFCgkydPJmJ3AIDuyCXA5MmTXXFxcfR1W1ubC4VCrqys7Lq14XDYSWIwGAxGNx/hcPiav+/jfgZ04cIFHThwQPn5+dFlffr0UX5+vqqqqq7YvrW1VZFIJGYAAHq+uAfQqVOn1NbWpszMzJjlmZmZamxsvGL7srIyBQKB6OAOOADoHczvgistLVU4HI6OhoYG65YAADdB3L8HlJ6err59+6qpqSlmeVNTk4LB4BXb+/1++f3+eLcBAOji4n4GlJSUpIkTJ6q8vDy6rL29XeXl5crNzY337gAA3VRCnoSwbNkyLVq0SPfdd58mT56s1atXq7m5WY888kgidgcA6IYSEkAPPfSQ/vvf/+rFF19UY2Ojvv/972vXrl1X3JgAAOi9fM45Z93Et0UiEQUCAes2AAA3KBwOKyUl5arrze+CAwD0TgQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBM9LNuAPb69evcYfD66697rpk+fbrnmgkTJniu6ax//OMfnmvq6uo81xw9etRzzdtvv+25pr6+3nONJLW1tXWqDvCCMyAAgAkCCABgIu4B9NJLL8nn88WMMWPGxHs3AIBuLiHXgO655x59/PHH/99JJ68xAAB6roQkQ79+/RQMBhPx1gCAHiIh14COHDmiUCik4cOHa+HChde846e1tVWRSCRmAAB6vrgHUE5OjjZs2KBdu3Zp7dq1qq+v1/3336+zZ892uH1ZWZkCgUB0DB48ON4tAQC6oLgHUFFRkR588EGNGzdOBQUF+stf/qIzZ87ogw8+6HD70tJShcPh6GhoaIh3SwCALijhdwekpqZq1KhRqq2t7XC93++X3+9PdBsAgC4m4d8DOnfunOrq6pSVlZXoXQEAupG4B9Czzz6ryspKffnll/r73/+uuXPnqm/fvnr44YfjvSsAQDcW94/gjh07pocfflinT5/WnXfeqalTp2rv3r268847470rAEA3FvcA2rRpU7zfEgk2derUTtX9+Mc/9lzz1FNPea5xznmuuZk687DUBx980HNNdXW155oPP/zQc40klZSUeK7hKxTwimfBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMOFzXexJj5FIRIFAwLqNXuW+++7rVF1n/sbTjh07OrUvSOPGjfNcs3nz5k7ta9u2bZ5rSktLO7Uv9FzhcFgpKSlXXc8ZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABE/DBnqwX/7yl52qe/PNNz3XBINBzzWRSMRzDboPnoYNAOiSCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOhn3QCAxMnKyupU3Zdffum5pqWlpVP7Qu/FGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATPIwUMODz+TzXTJgwwXPNI4884rlGkt555x3PNRcuXOjUvtB7cQYEADBBAAEATHgOoD179mjWrFkKhULy+Xzatm1bzHrnnF588UVlZWVp4MCBys/P15EjR+LVLwCgh/AcQM3NzRo/frzWrFnT4fpVq1bprbfe0rp167Rv3z7deuutKigo4I9VAQBieL4JoaioSEVFRR2uc85p9erV+vWvf63Zs2dLunQxMzMzU9u2bdOCBQturFsAQI8R12tA9fX1amxsVH5+fnRZIBBQTk6OqqqqOqxpbW1VJBKJGQCAni+uAdTY2ChJyszMjFmemZkZXXe5srIyBQKB6Bg8eHA8WwIAdFHmd8GVlpYqHA5HR0NDg3VLAICbIK4BFAwGJUlNTU0xy5uamqLrLuf3+5WSkhIzAAA9X1wDKDs7W8FgUOXl5dFlkUhE+/btU25ubjx3BQDo5jzfBXfu3DnV1tZGX9fX1+vw4cNKS0vTkCFD9PTTT+u1117T3XffrezsbL3wwgsKhUKaM2dOPPsGAHRzngNo//79mj59evT1smXLJEmLFi3Shg0btGLFCjU3N+vxxx/XmTNnNHXqVO3atUsDBgyIX9cAgG7P55xz1k18WyQSUSAQsG4DvVR6errnmnfffddzza233uq5ZsqUKZ5rrvaF8etZvny55xq+bI7LhcPha17XN78LDgDQOxFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATHj+cwxAT3bq1CnPNRUVFZ5r8vLyPNecO3fOc82gQYM810jSqFGjPNdUV1d3al/ovTgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYMLnnHPWTXxbJBJRIBCwbgPocn7+8597rlm4cGGn9vXAAw94rnn++ec916xbt85zDbqPcDislJSUq67nDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJHkYK4ApLlizxXPPGG294rlmwYIHnmj//+c+ea2CDh5ECALokAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJvpZNwCg61m3bp3nmq+//tpzzbvvvuu55vbbb/dcg66JMyAAgAkCCABgwnMA7dmzR7NmzVIoFJLP59O2bdti1i9evFg+ny9mFBYWxqtfAEAP4TmAmpubNX78eK1Zs+aq2xQWFurEiRPR8f77799QkwCAnsfzTQhFRUUqKiq65jZ+v1/BYLDTTQEAer6EXAOqqKhQRkaGRo8erSeeeEKnT5++6ratra2KRCIxAwDQ88U9gAoLC/XOO++ovLxcv/3tb1VZWamioiK1tbV1uH1ZWZkCgUB0DB48ON4tAQC6oLh/D2jBggXRn++9916NGzdOI0aMUEVFhWbMmHHF9qWlpVq2bFn0dSQSIYQAoBdI+G3Yw4cPV3p6umpraztc7/f7lZKSEjMAAD1fwgPo2LFjOn36tLKyshK9KwBAN+L5I7hz587FnM3U19fr8OHDSktLU1paml5++WXNnz9fwWBQdXV1WrFihUaOHKmCgoK4Ng4A6N48B9D+/fs1ffr06Otvrt8sWrRIa9euVXV1tf70pz/pzJkzCoVCmjlzpl599VX5/f74dQ0A6PZ8zjln3cS3RSIRBQIB6zYA3ATnz5/3XDNq1CjPNceOHfNcgxsXDoeveV2fZ8EBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEzE/U9yA8B3NXDgQM81I0aM8FzD07C7Js6AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOBhpADMRCIRzzX79u1LQCewwBkQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEzyMFEBcvPDCC55r/vOf/3iuaWlp8VyDrokzIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACZ4GCluqqSkJM81P/vZzzzXfPjhh55r8H+zZ8/2XNOZh5EOHTrUcw16Ds6AAAAmCCAAgAlPAVRWVqZJkyYpOTlZGRkZmjNnjmpqamK2aWlpUXFxse644w7ddtttmj9/vpqamuLaNACg+/MUQJWVlSouLtbevXu1e/duXbx4UTNnzlRzc3N0m6VLl2rHjh3asmWLKisrdfz4cc2bNy/ujQMAujdPNyHs2rUr5vWGDRuUkZGhAwcOKC8vT+FwWH/84x+1ceNG/ehHP5IkrV+/Xt/73ve0d+9e/fCHP4xf5wCAbu2GrgGFw2FJUlpamiTpwIEDunjxovLz86PbjBkzRkOGDFFVVVWH79Ha2qpIJBIzAAA9X6cDqL29XU8//bSmTJmisWPHSpIaGxuVlJSk1NTUmG0zMzPV2NjY4fuUlZUpEAhEx+DBgzvbEgCgG+l0ABUXF+vzzz/Xpk2bbqiB0tJShcPh6GhoaLih9wMAdA+d+iJqSUmJdu7cqT179mjQoEHR5cFgUBcuXNCZM2dizoKampoUDAY7fC+/3y+/39+ZNgAA3ZinMyDnnEpKSrR161Z98sknys7Ojlk/ceJE9e/fX+Xl5dFlNTU1Onr0qHJzc+PTMQCgR/B0BlRcXKyNGzdq+/btSk5Ojl7XCQQCGjhwoAKBgB599FEtW7ZMaWlpSklJ0ZNPPqnc3FzugAMAxPAUQGvXrpUkTZs2LWb5+vXrtXjxYknSm2++qT59+mj+/PlqbW1VQUGBfv/738elWQBAz+FzzjnrJr4tEokoEAhYt4EEeeWVVzzX+Hw+zzWdeTBmV9evn/dLtiUlJZ3a129+8xvPNWVlZZ5rXn31Vc816D7C4bBSUlKuup5nwQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATHTqL6ICnfXggw96rnnuuecS0ImtYcOGea555plnPNcUFxd7rpGkNWvWeK7pzBO00btxBgQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEDyPFTXXw4EHPNStXrvRcEwqFPNdI0hdffOG55gc/+IHnmtdee81zTU1NjeeaBQsWeK6RpI8++shzTVtbW6f2hd6LMyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmfM45Z93Et0UiEQUCAes2kCAjR470XLNixQrPNVOnTvVcI0ljxozxXNOZB6xu2rTJc83q1as913z99deea4B4CYfDSklJuep6zoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY4GGkAICE4GGkAIAuiQACAJjwFEBlZWWaNGmSkpOTlZGRoTlz5qimpiZmm2nTpsnn88WMJUuWxLVpAED35ymAKisrVVxcrL1792r37t26ePGiZs6cqebm5pjtHnvsMZ04cSI6Vq1aFdemAQDdXz8vG+/atSvm9YYNG5SRkaEDBw4oLy8vuvyWW25RMBiMT4cAgB7phq4BhcNhSVJaWlrM8vfee0/p6ekaO3asSktLdf78+au+R2trqyKRSMwAAPQCrpPa2trcT3/6UzdlypSY5X/4wx/crl27XHV1tXv33XfdXXfd5ebOnXvV91m5cqWTxGAwGIweNsLh8DVzpNMBtGTJEjd06FDX0NBwze3Ky8udJFdbW9vh+paWFhcOh6OjoaHBfNIYDAaDcePjegHk6RrQN0pKSrRz507t2bNHgwYNuua2OTk5kqTa2lqNGDHiivV+v19+v78zbQAAujFPAeSc05NPPqmtW7eqoqJC2dnZ1605fPiwJCkrK6tTDQIAeiZPAVRcXKyNGzdq+/btSk5OVmNjoyQpEAho4MCBqqur08aNG/WTn/xEd9xxh6qrq7V06VLl5eVp3LhxCfkHAAC6KS/XfXSVz/nWr1/vnHPu6NGjLi8vz6WlpTm/3+9Gjhzpli9fft3PAb8tHA6bf27JYDAYjBsf1/vdz8NIAQAJwcNIAQBdEgEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARJcLIOecdQsAgDi43u/zLhdAZ8+etW4BABAH1/t97nNd7JSjvb1dx48fV3Jysnw+X8y6SCSiwYMHq6GhQSkpKUYd2mMeLmEeLmEeLmEeLukK8+Cc09mzZxUKhdSnz9XPc/rdxJ6+kz59+mjQoEHX3CYlJaVXH2DfYB4uYR4uYR4uYR4usZ6HQCBw3W263EdwAIDegQACAJjoVgHk9/u1cuVK+f1+61ZMMQ+XMA+XMA+XMA+XdKd56HI3IQAAeodudQYEAOg5CCAAgAkCCABgggACAJjoNgG0Zs0aDRs2TAMGDFBOTo4+++wz65Zuupdeekk+ny9mjBkzxrqthNuzZ49mzZqlUCgkn8+nbdu2xax3zunFF19UVlaWBg4cqPz8fB05csSm2QS63jwsXrz4iuOjsLDQptkEKSsr06RJk5ScnKyMjAzNmTNHNTU1Mdu0tLSouLhYd9xxh2677TbNnz9fTU1NRh0nxneZh2nTpl1xPCxZssSo4451iwDavHmzli1bppUrV+rgwYMaP368CgoKdPLkSevWbrp77rlHJ06ciI6//vWv1i0lXHNzs8aPH681a9Z0uH7VqlV66623tG7dOu3bt0+33nqrCgoK1NLScpM7TazrzYMkFRYWxhwf77///k3sMPEqKytVXFysvXv3avfu3bp48aJmzpyp5ubm6DZLly7Vjh07tGXLFlVWVur48eOaN2+eYdfx913mQZIee+yxmONh1apVRh1fhesGJk+e7IqLi6Ov29raXCgUcmVlZYZd3XwrV65048ePt27DlCS3devW6Ov29nYXDAbdG2+8EV125swZ5/f73fvvv2/Q4c1x+Tw459yiRYvc7NmzTfqxcvLkSSfJVVZWOucu/bfv37+/27JlS3Sbf/3rX06Sq6qqsmoz4S6fB+ece+CBB9xTTz1l19R30OXPgC5cuKADBw4oPz8/uqxPnz7Kz89XVVWVYWc2jhw5olAopOHDh2vhwoU6evSodUum6uvr1djYGHN8BAIB5eTk9Mrjo6KiQhkZGRo9erSeeOIJnT592rqlhAqHw5KktLQ0SdKBAwd08eLFmONhzJgxGjJkSI8+Hi6fh2+89957Sk9P19ixY1VaWqrz589btHdVXe5hpJc7deqU2tralJmZGbM8MzNTX3zxhVFXNnJycrRhwwaNHj1aJ06c0Msvv6z7779fn3/+uZKTk63bM9HY2ChJHR4f36zrLQoLCzVv3jxlZ2errq5Ozz//vIqKilRVVaW+fftatxd37e3tevrppzVlyhSNHTtW0qXjISkpSampqTHb9uTjoaN5kKRf/OIXGjp0qEKhkKqrq/Xcc8+ppqZGH330kWG3sbp8AOH/ioqKoj+PGzdOOTk5Gjp0qD744AM9+uijhp2hK1iwYEH053vvvVfjxo3TiBEjVFFRoRkzZhh2lhjFxcX6/PPPe8V10Gu52jw8/vjj0Z/vvfdeZWVlacaMGaqrq9OIESNudpsd6vIfwaWnp6tv375X3MXS1NSkYDBo1FXXkJqaqlGjRqm2tta6FTPfHAMcH1caPny40tPTe+TxUVJSop07d+rTTz+N+fMtwWBQFy5c0JkzZ2K276nHw9XmoSM5OTmS1KWOhy4fQElJSZo4caLKy8ujy9rb21VeXq7c3FzDzuydO3dOdXV1ysrKsm7FTHZ2toLBYMzxEYlEtG/fvl5/fBw7dkynT5/uUceHc04lJSXaunWrPvnkE2VnZ8esnzhxovr37x9zPNTU1Ojo0aM96ni43jx05PDhw5LUtY4H67sgvotNmzY5v9/vNmzY4P75z3+6xx9/3KWmprrGxkbr1m6qZ555xlVUVLj6+nr3t7/9zeXn57v09HR38uRJ69YS6uzZs+7QoUPu0KFDTpL73e9+5w4dOuT+/e9/O+ece/31111qaqrbvn27q66udrNnz3bZ2dnuq6++Mu48vq41D2fPnnXPPvusq6qqcvX19e7jjz92EyZMcHfffbdraWmxbj1unnjiCRcIBFxFRYU7ceJEdJw/fz66zZIlS9yQIUPcJ5984vbv3+9yc3Ndbm6uYdfxd715qK2tda+88orbv3+/q6+vd9u3b3fDhw93eXl5xp3H6hYB5Jxzb7/9thsyZIhLSkpykydPdnv37rVu6aZ76KGHXFZWlktKSnJ33XWXe+ihh1xtba11Wwn36aefOklXjEWLFjnnLt2K/cILL7jMzEzn9/vdjBkzXE1NjW3TCXCteTh//rybOXOmu/POO13//v3d0KFD3WOPPdbj/ieto3+/JLd+/froNl999ZX71a9+5W6//XZ3yy23uLlz57oTJ07YNZ0A15uHo0ePury8PJeWlub8fr8bOXKkW758uQuHw7aNX4Y/xwAAMNHlrwEBAHomAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJv4HClemD2i425QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = np.random.randint(0, 60000)\n",
    "print(\"N:\", num)\n",
    "test_prediction(num, W1, b1, W2, b2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
